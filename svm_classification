import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import datasets
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Data Exploration and Preparation:
# Load the Iris dataset
iris = datasets.load_iris()
X = iris.data  # Features
y = iris.target  # Target

# Preprocessing:
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# SVM Implementation:
svm = SVC()
param_grid = {'kernel': ['linear', 'poly', 'rbf'],
              'C': [0.1, 1, 10],
              'gamma': ['scale', 'auto']}
grid_search = GridSearchCV(svm, param_grid, cv=5)
grid_search.fit(X_scaled, y)
best_svm = grid_search.best_estimator_

# K-fold Cross-Validation with Shuffling:
kf = KFold(n_splits=5, shuffle=True)
cv_scores = cross_val_score(best_svm, X_scaled, y, cv=kf, scoring='accuracy')

# Evaluation Metrics:
y_pred = best_svm.predict(X_scaled)
accuracy = accuracy_score(y, y_pred)
precision = precision_score(y, y_pred, average='macro')
recall = recall_score(y, y_pred, average='macro')
f1 = f1_score(y, y_pred, average='macro')

# Visualizations:
# EDA Visualization: Pairplot
df_iris = pd.DataFrame(data=np.c_[iris['data'], iris['target']], columns=iris['feature_names'] + ['target'])
sns.pairplot(df_iris, hue='target')
plt.suptitle('Pairplot of Iris Dataset Features')
plt.show()

# Model Performance Comparison: Cross-Validation Scores
plt.figure(figsize=(8, 6))
plt.bar(range(len(cv_scores)), cv_scores, color='skyblue')
plt.xlabel('Fold')
plt.ylabel('Accuracy')
plt.title('Cross-Validation Scores for SVM Model')
plt.ylim(0, 1)
plt.show()

# Evaluation Metrics Visualization: Confusion Matrix
from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(y, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.xlabel('Predicted label')
plt.ylabel('True label')
plt.title('Confusion Matrix')
plt.show()

# Print evaluation metrics
print(f'Accuracy: {accuracy}')
print(f'Precision: {precision}')
print(f'Recall: {recall}')
print(f'F1 Score: {f1}')
print(f'Cross-Validation Scores: {cv_scores}')
